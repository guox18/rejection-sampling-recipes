#!/usr/bin/env python3
"""
SFT Recipe æ‰§è¡Œå…¥å£.

Usage:
    # å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆé»˜è®¤åœ¨è¾“å…¥æ–‡ä»¶çš„çˆ¶ç›®å½•ä¸‹åˆ›å»º sft/timestamp/ å­ç›®å½•ï¼‰
    python run.py --input data/train.jsonl
    # è¾“å‡º: data/sft/YYYYMMDD_HHMMSS/sft_train.jsonl

    # å¤„ç†å¤šä¸ªæ–‡ä»¶ï¼ˆå¤ç”¨åŒä¸€ä¸ª Ray sessionï¼‰
    python run.py --input data/train.jsonl data/test.jsonl data/val.jsonl
    # è¾“å‡º: data/sft/YYYYMMDD_HHMMSS/sft_train.jsonl
    #       data/sft/YYYYMMDD_HHMMSS/sft_test.jsonl
    #       data/sft/YYYYMMDD_HHMMSS/sft_val.jsonl

    # è‡ªå®šä¹‰è¾“å‡ºç›®å½•
    python run.py --input data/*.jsonl --output-dir results/exp001
    # è¾“å‡º: results/exp001/sft_YYYYMMDD_HHMMSS/sft_*.jsonl

    # è¿æ¥åˆ° Ray é›†ç¾¤
    python run.py --input data/*.jsonl --ray-address auto
"""

import os

# ç¦ç”¨ Ray runtime_env è‡ªåŠ¨æ£€æµ‹(å…±äº«é¡¹ç›®è·¯å¾„, ä¸éœ€è¦ä¼ è¾“ä»£ç )
os.environ.setdefault("RAY_RUNTIME_ENV_HOOK_ENABLED", "0")

# å±è”½ Ray çš„å„ç§è­¦å‘Šä¿¡æ¯
os.environ.setdefault("RAY_DISABLE_DOCKER_CPU_WARNING", "1")
os.environ.setdefault("RAY_DISABLE_MEMORY_MONITOR", "1")
os.environ.setdefault("RAY_LOG_TO_STDERR", "0")
os.environ.setdefault("PYTHONWARNINGS", "ignore")  # å±è”½ Python è­¦å‘Š

import argparse
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = os.path.dirname(
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
)
sys.path.insert(0, PROJECT_ROOT)

import ray

from recipes.sft.config import SFTConfig
from recipes.sft.recipe import SFTRecipe
from src.pipeline import Pipeline


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°."""
    parser = argparse.ArgumentParser(
        description="SFT Recipe: é‡‡æ · â†’ éªŒè¯ â†’ æ ¼å¼åŒ–",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    # æ•°æ®è·¯å¾„
    parser.add_argument(
        "--input",
        "-i",
        type=str,
        nargs="+",  # æ”¯æŒå¤šä¸ªè¾“å…¥æ–‡ä»¶
        default=[
            os.path.join(PROJECT_ROOT, "tests/mock/text.jsonl"),
            os.path.join(PROJECT_ROOT, "tests/mock/text-pic.jsonl"),
        ],
        help="è¾“å…¥æ•°æ®è·¯å¾„ (JSONL æ ¼å¼)ï¼Œæ”¯æŒå¤šä¸ªæ–‡ä»¶",
    )
    parser.add_argument(
        "--output-dir",
        "-o",
        type=str,
        default=None,
        help="è¾“å‡ºç›®å½•ã€‚å¦‚æœæŒ‡å®šï¼Œä¼šåœ¨æ­¤ç›®å½•ä¸‹åˆ›å»º sft_YYYYMMDD_HHMMSS/ å­ç›®å½•ï¼›å¦‚æœä¸æŒ‡å®šï¼Œä¼šåœ¨è¾“å…¥æ–‡ä»¶çš„çˆ¶ç›®å½•ä¸‹åˆ›å»º sft/YYYYMMDD_HHMMSS/ å­ç›®å½•",
    )
    parser.add_argument(
        "--output-suffix",
        type=str,
        default="_sft",
        help="è¾“å‡ºæ–‡ä»¶ååç¼€ï¼Œä¾‹å¦‚ train.jsonl -> train_sft.jsonl",
    )
    parser.add_argument(
        "--latest",
        action="store_true",
        help="ä»è¾“å‡ºç›®å½•ä¸‹çš„æœ€æ–°æ—¶é—´æˆ³ç›®å½•ç»­ä¼ ã€‚å¦‚æœæ‰¾ä¸åˆ°å·²æœ‰çš„ sft_YYYYMMDD_HHMMSS ç›®å½•ï¼Œåˆ™åˆ›å»ºæ–°çš„",
    )
    parser.add_argument(
        "--config",
        "-c",
        type=str,
        default=os.path.join(os.path.dirname(os.path.dirname(__file__)), "config.yaml"),
        help="é…ç½®æ–‡ä»¶è·¯å¾„",
    )

    # Pipeline é…ç½®(å¯è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼)
    parser.add_argument(
        "--batch-size",
        type=int,
        default=None,
        help="æ¯ä¸ª batch çš„æ•°æ®é‡(è¦†ç›–é…ç½®æ–‡ä»¶)",
    )
    parser.add_argument(
        "--concurrency",
        type=int,
        default=None,
        help="é»˜è®¤å¹¶å‘åº¦, ä»…å¯¹æ²¡æœ‰é…ç½®å¹¶å‘åº¦çš„ Stages èµ·ä½œç”¨(Stage çš„ actor æ•°é‡, è¦†ç›–é…ç½®æ–‡ä»¶)",
    )
    parser.add_argument(
        "--sampler-concurrency",
        type=int,
        default=None,
        help="SamplerStage å¹¶å‘åº¦(è¦†ç›–é…ç½®æ–‡ä»¶)",
    )
    parser.add_argument(
        "--verifier-concurrency",
        type=int,
        default=None,
        help="VerifierStage å¹¶å‘åº¦(è¦†ç›–é…ç½®æ–‡ä»¶)",
    )

    # Ray é…ç½®
    parser.add_argument(
        "--ray-address",
        type=str,
        default=None,
        help="Ray é›†ç¾¤åœ°å€. ä¸æŒ‡å®šåˆ™å¯åŠ¨æœ¬åœ°æ¨¡å¼ï¼›'auto' è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹ï¼›æˆ–æŒ‡å®š 'ray://IP:10001'",
    )
    parser.add_argument(
        "--num-cpus",
        type=int,
        default=None,
        help="Ray æœ¬åœ°æ¨¡å¼ä½¿ç”¨çš„ CPU æ•°é‡(ä»…åœ¨ --ray-address æœªæŒ‡å®šæ—¶ç”Ÿæ•ˆ)",
    )
    parser.add_argument(
        "--num-gpus",
        type=int,
        default=None,
        help="Ray æœ¬åœ°æ¨¡å¼ä½¿ç”¨çš„ GPU æ•°é‡(ä»…åœ¨ --ray-address æœªæŒ‡å®šæ—¶ç”Ÿæ•ˆ)",
    )

    # å…¶ä»–é€‰é¡¹
    parser.add_argument(
        "--no-resume",
        action="store_true",
        help="ç¦ç”¨æ–­ç‚¹ç»­ä¼ , é‡æ–°å¤„ç†æ‰€æœ‰æ•°æ®",
    )
    parser.add_argument(
        "--no-preserve-order",
        action="store_true",
        help="ç¦ç”¨é¡ºåºä¿æŒ, å¯æé«˜æ€§èƒ½ä½†è¾“å‡ºé¡ºåºå¯èƒ½ä¸ä¸€è‡´",
    )

    return parser.parse_args()


def init_ray(args: argparse.Namespace) -> None:
    """åˆå§‹åŒ– Ray."""
    if ray.is_initialized():
        print(f"âœ… Ray å·²åˆå§‹åŒ–, ä½¿ç”¨ç°æœ‰è¿æ¥")
        return

    # å…±äº«å­˜å‚¨æ¨¡å¼ï¼šç¦ç”¨ runtime_env, ä¸éœ€è¦ Ray ä¼ è¾“ä»£ç , æ‰€æœ‰èŠ‚ç‚¹ç›´æ¥è®¿é—®å…±äº«å­˜å‚¨ä¸Šçš„é¡¹ç›®
    init_kwargs = {
        "runtime_env": {},
        "logging_level": "ERROR",  # åªæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯, å±è”½è­¦å‘Š
        "log_to_driver": False,  # ç¦ç”¨é©±åŠ¨ç¨‹åºæ—¥å¿—è¾“å‡º
    }

    if args.ray_address:
        # è¿æ¥åˆ°å·²æœ‰é›†ç¾¤
        print(f"ğŸ”— è¿æ¥åˆ° Ray é›†ç¾¤: {args.ray_address}")
        init_kwargs["address"] = args.ray_address
    else:
        # æœ¬åœ°æ¨¡å¼
        if args.num_cpus is not None:
            init_kwargs["num_cpus"] = args.num_cpus
        if args.num_gpus is not None:
            init_kwargs["num_gpus"] = args.num_gpus
        print(f"ğŸš€ å¯åŠ¨ Ray æœ¬åœ°æ¨¡å¼")

    ray.init(**init_kwargs)

    # æ‰“å°é›†ç¾¤ä¿¡æ¯
    resources = ray.cluster_resources()
    print(f"   CPU: {resources.get('CPU', 0):.0f}")
    print(f"   GPU: {resources.get('GPU', 0):.0f}")
    print(f"   Memory: {resources.get('memory', 0) / 1e9:.1f} GB")


def find_latest_timestamp_dir(output_dir: str) -> str | None:
    """
    åœ¨è¾“å‡ºç›®å½•ä¸‹æŸ¥æ‰¾æœ€æ–°çš„æ—¶é—´æˆ³ç›®å½• (YYYYMMDD_HHMMSS æ ¼å¼).

    Args:
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„

    Returns:
        æœ€æ–°æ—¶é—´æˆ³ç›®å½•çš„å®Œæ•´è·¯å¾„ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å› None
    """
    if not os.path.exists(output_dir):
        return None

    # æ‰¾æ‰€æœ‰æ—¶é—´æˆ³æ ¼å¼çš„å­ç›®å½• (YYYYMMDD_HHMMSS: 8ä½æ—¥æœŸ_6ä½æ—¶é—´)
    timestamp_dirs = []
    for item in os.listdir(output_dir):
        item_path = os.path.join(output_dir, item)
        if os.path.isdir(item_path) and len(item) == 15 and item[8] == "_":
            # ç®€å•æ£€æŸ¥ï¼šé•¿åº¦15ï¼Œç¬¬9ä¸ªå­—ç¬¦æ˜¯ä¸‹åˆ’çº¿
            timestamp_dirs.append(item)

    if not timestamp_dirs:
        return None

    # æŒ‰å­—ç¬¦ä¸²æ’åºï¼Œæ—¶é—´æˆ³æ ¼å¼å¤©ç„¶å¯æ’åºï¼Œæœ€æ–°çš„åœ¨æœ€å
    latest = sorted(timestamp_dirs)[-1]
    latest_path = os.path.join(output_dir, latest)
    return latest_path


def generate_output_path(input_path: str, output_dir: str, suffix: str) -> str:
    """
    æ ¹æ®è¾“å…¥æ–‡ä»¶è·¯å¾„ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„.

    è§„åˆ™:
        - ä¿ç•™è¾“å…¥æ–‡ä»¶åï¼Œæ·»åŠ åç¼€
        - è¾“å‡ºæ–‡ä»¶æ”¾åœ¨ output_dir ç›®å½•ä¸‹

    ç¤ºä¾‹:
        è¾“å…¥: a/b/c/train.jsonl    â†’ output_dir/train_sft.jsonl
    """
    input_filename = os.path.basename(input_path)
    name_without_ext = os.path.splitext(input_filename)[0]
    output_filename = f"{name_without_ext}{suffix}.jsonl"

    return os.path.join(output_dir, output_filename)


def main():
    """è¿è¡Œ SFT Recipe."""
    args = parse_args()

    # å¤„ç†è¾“å…¥æ–‡ä»¶åˆ—è¡¨
    input_files = args.input if isinstance(args.input, list) else [args.input]

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    for input_file in input_files:
        if not os.path.exists(input_file):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            sys.exit(1)

    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not os.path.exists(args.config):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        sys.exit(1)

    # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºè·¯å¾„
    from datetime import datetime

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # å†³å®šè¾“å‡ºè·¯å¾„
    if args.output_dir:
        # ç”¨æˆ·æŒ‡å®šäº†è¾“å‡ºç›®å½•
        if args.latest:
            # å°è¯•ä»æœ€æ–°æ—¶é—´æˆ³ç›®å½•ç»­ä¼ 
            latest_dir = find_latest_timestamp_dir(args.output_dir)
            if latest_dir:
                output_base_dir = latest_dir
            else:
                output_base_dir = os.path.join(args.output_dir, f"sft_{timestamp}")
        else:
            # ç›´æ¥åˆ›å»ºæ–°çš„æ—¶é—´æˆ³ç›®å½•
            output_base_dir = os.path.join(args.output_dir, f"sft_{timestamp}")

        output_files = [
            generate_output_path(input_file, output_base_dir, args.output_suffix)
            for input_file in input_files
        ]
    else:
        # ç”¨æˆ·æ²¡æœ‰æŒ‡å®šè¾“å‡ºç›®å½•ï¼šæ¯ä¸ªè¾“å…¥æ–‡ä»¶åœ¨è‡ªå·±çš„çˆ¶ç›®å½•ä¸‹åˆ›å»º sft/YYYYMMDD_HHMMSS/
        output_files = []
        for input_file in input_files:
            input_dir = os.path.dirname(os.path.abspath(input_file))
            sft_base_dir = os.path.join(input_dir, "sft")

            if args.latest:
                # å°è¯•ä»æœ€æ–°æ—¶é—´æˆ³ç›®å½•ç»­ä¼ 
                latest_dir = find_latest_timestamp_dir(sft_base_dir)
                if latest_dir:
                    output_base_dir = latest_dir
                else:
                    output_base_dir = os.path.join(sft_base_dir, timestamp)
            else:
                output_base_dir = os.path.join(sft_base_dir, timestamp)

            output_file = generate_output_path(input_file, output_base_dir, args.output_suffix)
            output_files.append(output_file)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    for output_file in output_files:
        os.makedirs(os.path.dirname(output_file), exist_ok=True)

    # åŠ è½½é…ç½®
    config = SFTConfig.from_yaml(args.config)

    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®æ–‡ä»¶(è‡ªåŠ¨æ£€æµ‹æ‰€æœ‰åŒ¹é…çš„å‚æ•°)
    for key in dir(config):
        if not key.startswith("_") and hasattr(args, key):
            arg_value = getattr(args, key, None)
            if arg_value is not None:
                setattr(config, key, arg_value)

    # å¤„ç†é»˜è®¤å€¼ï¼šsampler/verifier_concurrency é»˜è®¤ä½¿ç”¨ concurrency
    config.sampler_concurrency = config.sampler_concurrency or config.concurrency
    config.verifier_concurrency = config.verifier_concurrency or config.concurrency

    print("=" * 60)
    print("SFT Recipe")
    print("=" * 60)
    print(f"  Config:      {args.config}")
    print(f"  Model:       {config.model}")
    print(f"  Base URL:    {config.base_url}")
    print(f"  N Samples:   {config.n_samples}")
    print(f"  Batch Size:  {config.batch_size}")
    print(f"  Concurrency: {config.concurrency}")
    print(f"  Sampler:     {config.sampler_concurrency}")
    print(f"  Verifier:    {config.verifier_concurrency}")
    print(
        f"  Resume:      {'Latest' if args.latest else 'Disabled' if args.no_resume else 'Enabled'}"
    )
    print(f"  Files:       {len(input_files)}")
    print("=" * 60)

    # æ˜¾ç¤ºè¾“å…¥è¾“å‡ºæ˜ å°„ï¼ˆç®€åŒ–è·¯å¾„æ˜¾ç¤ºï¼‰
    print("\nğŸ“ Output Directory:")
    # å–ç¬¬ä¸€ä¸ªè¾“å‡ºæ–‡ä»¶çš„ç›®å½•ä½œä¸ºä»£è¡¨
    if output_files:
        output_dir_display = os.path.dirname(output_files[0])
        print(f"  {output_dir_display}")
        print(
            f"\n  Files: {len(output_files)} â†’ {', '.join([os.path.basename(f) for f in output_files[:3]])}"
        )
        if len(output_files) > 3:
            print(f"         ... and {len(output_files) - 3} more")
    print()

    # åˆå§‹åŒ– Rayï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼Œæ‰€æœ‰æ–‡ä»¶å¤ç”¨ï¼‰
    init_ray(args)

    # åˆ›å»º Recipeï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼‰
    recipe = SFTRecipe(config)

    # åˆ›å»º Pipelineï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼‰
    pipeline = Pipeline(
        recipe=recipe,
        batch_size=config.batch_size,
        concurrency=config.concurrency,
        stage_concurrency={
            "SamplerStage": config.sampler_concurrency,
            "VerifierStage": config.verifier_concurrency,
            "FormatterStage": 1,
        },
        preserve_order=not args.no_preserve_order,
        resume=not args.no_resume,
    )

    # å¾ªç¯å¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼ˆå¤ç”¨åŒä¸€ä¸ª Ray session å’Œ Pipelineï¼‰
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ Pipeline...\n")

    total_success = 0
    total_failed = 0

    for i, (input_file, output_file) in enumerate(zip(input_files, output_files), 1):
        print("=" * 60)
        print(f"Processing file {i}/{len(input_files)}: {os.path.basename(input_file)}")
        print("=" * 60)

        try:
            pipeline.run(input_file, output_file)
            total_success += 1
        except Exception as e:
            print(f"âŒ Failed to process {input_file}: {e}")
            total_failed += 1

        print()

    # æ€»ç»“
    print("=" * 60)
    print("ğŸ“Š Final Summary")
    print("=" * 60)
    print(f"  Total files:     {len(input_files)}")
    print(f"  Success:         {total_success}")
    print(f"  Failed:          {total_failed}")
    print("=" * 60)
    print()
    print("âœ… All files processed!")


if __name__ == "__main__":
    main()
