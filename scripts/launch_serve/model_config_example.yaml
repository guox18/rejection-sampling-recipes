# 模型服务配置文件 - 包含所有可用模型的配置
# 用法: bash start_vllm_service.sh --config model_config.yaml --model <模型名称> --router-ip <IP> --router-port <PORT>

# Qwen3 VL 235B Instruct 模型
qwen3_vl_235b_a22b_instruct:
  tp: 8                    # 张量并行度
  dp: 1                    # 数据并行度
  pp: 1                    # 流水线并行度
  worker_count: 1          # Worker 数量
  memory_per_task: 1200    # 每个任务的内存 (MB)
  cpus_per_task: 32        # 每个任务的 CPU 核心数
  model_path: "/mnt/shared-storage-user/large-model-center-share-weights/hf_hub/models--Qwen--Qwen3-VL-235B-A22B-Instruct/snapshots/a85c31584af63f6e55c91d93bda2ae78600e1a77"

# Qwen3 VL 235B Thinking 模型
qwen3_vl_235b_a22b_thinking:
  tp: 8
  dp: 1
  pp: 1
  worker_count: 1
  memory_per_task: 1200
  cpus_per_task: 32
  model_path: "/mnt/shared-storage-user/large-model-center-share-weights/hf_hub/models--Qwen--Qwen3-VL-235B-A22B-Thinking/snapshots/xxx"

# Qwen 72B 模型示例 (较小的模型，使用更少的 GPU)
qwen2_72b_instruct:
  tp: 4
  dp: 1
  pp: 1
  worker_count: 1
  memory_per_task: 600
  cpus_per_task: 16
  model_path: "/mnt/shared-storage-user/large-model-center-share-weights/hf_hub/models--Qwen--Qwen2-72B-Instruct/snapshots/xxx"


